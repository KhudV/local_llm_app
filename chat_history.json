{
  "chats": {
    "Чат 1": {
      "messages": [
        {
          "role": "user",
          "content": "Write a program to calculate PageRank of every node in a given graph."
        },
        {
          "role": "assistant",
          "content": "<think>\nOkay, so I need to write a program to calculate the PageRank of every node in a given graph. Hmm, where do I start? I remember that PageRank is an algorithm used by Google to rank web pages. The idea is that a page is important if it's linked by other important pages. \n\nFirst, I should probably understand how PageRank works mathematically. From what I recall, it involves a transition matrix and some linear algebra. Each node's PageRank is determined by the sum of the PageRanks of all its incoming links, each divided by the number of outgoing links from that node. It sounds like an iterative process because the ranks propagate through the graph.\n\nI think the formula goes something like this: PR(i) = (1 - d) + d * sum(PR(j)/outdegree(j)) for all j that point to i, where d is a damping factor usually around 0.85 to 0.95. Oh right, the damping factor accounts for the probability of the user randomly jumping to any page.\n\nSo, I need to represent the graph in a way that captures both incoming and outgoing links. Maybe an adjacency list would work, where each node has a list of nodes it points to (outgoing) and another list of nodes pointing to it (incoming). That might help in calculating the contributions from each incoming link.\n\nWait, but for PageRank specifically, I think we can represent the graph using its adjacency matrix. Each entry A[i][j] is 1 if there's a link from i to j, and 0 otherwise. Then, the transition matrix T would be such that T[i][j] = A[i][j]/outdegree(i). So each row in T sums up to 1 because it's normalized by the number of outgoing links.\n\nThe PageRank vector PR is then the stationary distribution of this Markov chain, which means it satisfies PR = d * T^T * PR + (1 - d) * S, where S is a vector of equal probabilities. Since all nodes are equally likely to be chosen with probability 1/n when following a random link, S would have each entry as 1/n.\n\nThis leads me to think that PageRank can be computed using an iterative method called the power method. Starting with an initial guess for PR (like all ones divided by n), we keep multiplying by T^T and adding (1 - d) * S until the vector converges within a certain tolerance.\n\nSo, the steps I need to follow are:\n\n1. Read the graph data and build the adjacency matrix or lists.\n2. Compute the transition matrix T by normalizing each row of A by the outdegree of each node.\n3. Initialize the PageRank vector PR with uniform probabilities (like 1/n for each node).\n4. Iteratively update PR using PR = d * T^T multiplied by PR plus (1 - d) times S, until the change between iterations is below a threshold (like 1e-6 or something small).\n5. Output the final PageRank values.\n\nBut wait, how do I represent the graph? If it's given as an adjacency list where each node has its outgoing links, that would be useful for constructing T. For each node i, outdegree(i) is just the length of its outgoing list. The transition matrix can then be built by dividing each entry A[i][j] by outdegree(i).\n\nAlternatively, if the graph is represented as an adjacency matrix, I can compute the outdegrees from each row's sum.\n\nNow, thinking about implementation in code:\n\n- I'll need to read input that represents the graph. Maybe it's given as a list of edges, where each edge is a pair (i, j) indicating i points to j.\n- Then, for each node, I can build its outgoing and incoming links. But for PageRank, mainly the outgoing links are needed because we're building T from them.\n\nWait, actually, in T, each row corresponds to the outgoing probabilities from that node. So if a node has no outgoing links (like a sink), then all its probability would stay within itself or get damped by (1 - d). But I think in practice, such nodes are treated as having their probability distributed equally among themselves.\n\nBut for now, let's assume all nodes have outgoing links to avoid dealing with that edge case. Or perhaps the code should handle cases where outdegree is zero by setting T[i][i] = 1 or something like that.\n\nNext, how do I represent T? Maybe as a list of dictionaries or lists, but in Python, using numpy arrays might be more efficient for matrix operations.\n\nBut since the power method involves vector multiplications, perhaps it's better to represent T as a sparse matrix or just compute the contributions on the fly without explicitly building the full matrix. That could save memory and computation time, especially for large graphs.\n\nWait, let me think: in each iteration of the power method, I have PR = d * T^T @ PR + (1 - d) * S.\n\nSo, to compute this efficiently without storing the entire transition matrix, which can be very large, maybe I can represent T as an adjacency list. For each node i, I have a list of nodes j that it points to. Then, for the term d * T^T @ PR, since T^T is the transpose, each entry (j, i) in T corresponds to (i, j) in T^T. So, when computing the new PR[j], I sum over all i such that there's an edge from i to j, multiplied by PR[i] / outdegree(i).\n\nSo perhaps for each node j, I can collect all nodes i that point to j and then compute their contributions.\n\nThis approach would be more memory-efficient because it doesn't require storing the entire matrix. Instead, for each node j, we have a list of its incoming edges (from nodes i), which can be precomputed before starting the iterations.\n\nSo the steps in code:\n\n1. Read the graph and build adjacency lists:\n   - For each edge (i, j), add j to outgoing[i] and add i to incoming[j].\n   - Also, compute outdegree for each node as len(outgoing[i]).\n\n2. Precompute a list for each node j of all nodes i that point to j. This is the incoming list for j.\n\n3. Initialize PR as a vector where each entry is 1/n.\n\n4. For each iteration:\n   a. Compute the damping term: (1 - d) * S, which is just adding (1 - d)/n to each node's new rank.\n   b. For each node j, compute the sum over all i in incoming[j] of (PR[i] / outdegree[i]). Multiply this sum by d and add it to the damping term to get the new PR[j].\n\n5. Continue iterating until the change between successive PR vectors is less than a certain epsilon.\n\nNow, how do I handle nodes with zero outdegree? Because if a node has no outgoing edges (outdegree = 0), then in the transition matrix, T[i] would have all zeros except for maybe itself. But according to PageRank's rules, such nodes should contribute their probability back to themselves or others based on damping.\n\nWait, actually, in the standard implementation, if a node has zero outdegree, it's treated as pointing to itself. So when computing T, if outdegree[i] is zero, we set T[i][i] = 1. That way, the probability doesn't disappear but stays within the node.\n\nSo I need to modify step 2: for each i, check if outgoing[i] is empty. If it is, then add i to outgoing[i], effectively creating a self-loop. Alternatively, during the computation of outdegree[i], if it's zero, treat it as having an outdegree of 1 (itself) and include itself in the incoming list.\n\nHmm, but that might complicate things because the incoming lists would have to include i for such nodes. Maybe during preprocessing, I can adjust outgoing[i] to include i when its outdegree is zero. Or perhaps handle it on the fly during the PageRank computation.\n\nBut perhaps it's easier to precompute it: after building outgoing and incoming lists, for each node i, if len(outgoing[i]) == 0, add i to outgoing[i], and also ensure that in the incoming list of i, it's included (since it points to itself). Or wait, no: adding a self-loop would make outgoing[i] include i, but does that affect incoming[j]? Only for j=i.\n\nWait, if I have an edge from i to i, then when building the incoming list for node i, it will include i as one of its sources. So when processing incoming[i], we'll have all nodes pointing to i, including itself.\n\nBut in the case where a node has no outgoing edges except itself, during the transition matrix computation, T[i][i] = 1/outdegree(i) which is 1/1=1, so it's correct.\n\nOkay, so I should adjust the outgoing lists: for each i, if len(outgoing[i]) == 0, append i to outgoing[i]. That way, the node points to itself, and thus in T, it contributes its PR to itself.\n\nSo that's an important step. I need to make sure that all nodes have at least one outgoing edge (pointing to themselves) to prevent division by zero when computing outdegree[i].\n\nOnce I have the outgoing lists adjusted, I can proceed with the rest of the algorithm.\n\nNow, coding this in Python:\n\nI'll represent the graph using adjacency lists. Let's say the number of nodes is n.\n\nRead the edges: for each edge (u, v), add v to outgoing[u], and u to incoming[v].\n\nThen, adjust outgoing[u] for each u: if len(outgoing[u]) == 0, append u to outgoing[u]. This ensures that outdegree[u] >=1.\n\nCompute outdegree[i] = len(outgoing[i]) for each i.\n\nInitialize PR as [1/n] * n.\n\nSet a damping factor d, say 0.85.\n\nSet a tolerance epsilon, like 1e-6 or something small to determine when the changes are negligible.\n\nIterate until the change is below epsilon:\n\n   new_PR = (1 - d) * S + d * T^T @ PR\n\nBut in code terms, for each j in 0..n-1:\n   sum_contribution = sum( PR[i] / outdegree[i] for i in incoming[j] )\n   new_PR[j] = (1 - d)/n + d * sum_contribution\n\nWait, no. S is a vector where all entries are (1 - d)/n. So the damping term is added to each node.\n\nSo:\n\nnew_PR[j] = (1 - d) / n + d * sum_contribution\n\nYes, that makes sense.\n\nThen, compute the difference between new_PR and PR for all nodes. If the maximum absolute difference is less than epsilon, break.\n\nOtherwise, set PR = new_PR and repeat.\n\nBut wait, in the first iteration, PR is [1/n] * n, so when you multiply by d and T^T, plus (1 - d)/n, it's effectively the same as adding (d * ... + (1 - d)/n). So that's correct.\n\nNow, coding this:\n\nRead the number of nodes, say n. Then read m edges.\n\nBuild outgoing and incoming lists.\n\nAdjust outgoing lists for zero outdegree.\n\nCompute outdegrees.\n\nInitialize PR.\n\nSet d = 0.85, epsilon = 1e-6.\n\nIterate until convergence:\n\n   Compute new_PR as a list where each entry is (1 - d)/n plus d times the sum of (PR[i]/outdegree[i]) for all i in incoming[j].\n\nThen compare PR and new_PR to see if they have converged.\n\nNow, let's think about possible issues:\n\n- Nodes are 0-indexed? Or 1-indexed? The code should handle whatever input is given, but probably easier to make them 0-based.\n\n- Handling nodes with no outgoing edges except themselves: as we've added self-loops during preprocessing, this shouldn't be a problem.\n\n- Sparse graphs: for large n, the incoming lists per node may be small. So the inner loop of summing over i in incoming[j] is manageable.\n\n- Convergence speed: depending on the graph structure and d, it can take varying numbers of iterations. But typically, it's said to converge quickly enough for practical purposes.\n\nAnother thing to consider: the initial PR vector is uniform, but maybe a better starting point would be using a seed like all ones or something else. But I think the standard approach is to start uniformly.\n\nAlso, in practice, some implementations use teleportation (the damping term) only when following links, not adding it as a constant. Wait, no—the formula is PR = d * T^T * PR + (1 - d)*S, so that's correct.\n\nWait, actually, the PageRank formula can be written as:\n\nPR(i) = sum_{j -> i} (d * PR(j)/outdegree(j)) + (1 - d)\n\nBut no, I think it's scaled by n: because if you have all nodes pointing to themselves and d=0.85, each node would contribute 0.85*(sum of incoming) / n?\n\nWait, maybe not. Let me get back to the formula.\n\nThe correct equation is:\n\nPR(i) = (1 - d)/n + d * sum_{j -> i} PR(j)/outdegree(j)\n\nYes, that's right. So each node j contributes d * PR(j)/outdegree(j) to node i, and then we add the damping term (1 - d)/n.\n\nSo in code:\n\nnew_PR[j] = (1 - d)/n + d * sum( PR[i]/outdegree[i] for i in incoming[j] )\n\nYes.\n\nNow, writing this in Python:\n\nRead n and m.\n\noutgoing = [[] for _ in range(n)]\nincoming = [[] for _ in range(n)]\n\nfor each of the m edges:\n    u, v = map(int, input().split())\n    outgoing[u].append(v)\n    incoming[v].append(u)\n\n# Adjust outgoing lists for nodes with zero outdegree\nfor i in range(n):\n    if len(outgoing[i]) == 0:\n        outgoing[i].append(i)  # add self-loop\n\noutdegrees = [len(lst) for lst in outgoing]\n\nd = 0.85\nepsilon = 1e-6\n\nPR = [1.0 / n] * n\n\nwhile True:\n    new_PR = [(1 - d)/n] * n  # initialize with damping term\n    for j in range(n):\n        sum_contribution = 0.0\n        for i in incoming[j]:\n            sum_contribution += PR[i] / outdegrees[i]\n        new_PR[j] += d * sum_contribution\n\n    # Check convergence\n    max_diff = max( abs(new_PR[j] - PR[j]) for j in range(n) )\n    if max_diff < epsilon:\n        break\n    PR = new_PR.copy()\n\nWait, no. Wait, the code above initializes new_PR as [(1 - d)/n] * n and then adds d*sum_contribution to each j.\n\nBut that's not correct because (1 - d)/n is added once per node, but in reality, it's a constant term for all nodes: (1 - d) times 1/n. So the initial new_PR should be [ (1 - d)/n ] * n as a list, and then each j adds d*sum_contribution.\n\nYes, that seems correct.\n\nBut wait, no—each node j gets its own contribution, so it's:\n\nnew_PR[j] = (1 - d) / n + d * sum( ... )\n\nWhich is exactly what the code does. Because new_PR starts as [ (1-d)/n ] for all j, and then adds d*sum_contribution.\n\nSo yes, that part is correct.\n\nBut in Python, when you do new_PR = [(1 - d)/n] * n, it creates a list where each element points to the same float object. So when you modify any of them via new_PR[j] += ..., all elements will change? No, because in Python, the multiplication creates multiple references to the same value.\n\nWait, no: (1 - d)/n is a number, and [(1 - d)/n] * n makes a list where each element is that number. So when you do new_PR[j] += something, it's equivalent to new_PR[j] = new_PR[j] + something. Since the initial value is (1 -d)/n for all j, adding to each j will keep them as separate values.\n\nWait no: because in Python, list elements are references to objects. So if you have a list [x] * n, and x is an integer or float, then all elements point to the same x object. But when you do new_PR[j] += something, it's equivalent to new_PR[j] = new_PR[j] + something, which creates a new value for that element.\n\nWait, no: in Python, integers are immutable, so [x]*n would have multiple references to the same integer x. For floats, which are also immutable, the same applies. So when you do new_PR[j] += d * sum_contribution, it's equivalent to new_PR[j] = new_PR[j] + ..., which creates a new float object and assigns it to new_PR[j]. Therefore, each element of new_PR can have different values.\n\nSo the code is correct in initializing new_PR as [(1 - d)/n] * n because each j starts with that value, then adds its own contribution.\n\nTherefore, the code should work.\n\nBut let's test it on a small example to see if it works.\n\nExample: A graph with two nodes, A and B (0 and 1), where A points to B, and B points back to A. So edges are (0, 1) and (1, 0). Both have outdegree 1.\n\nSo n=2, m=2.\n\noutgoing[0] = [1], outgoing[1] = [0]\n\nincoming[0] = [1], incoming[1] = [0]\n\nCompute PR:\n\nInitially, PR = [0.5, 0.5]\n\nFirst iteration:\n\nnew_PR[j] = (1 - d)/2 + d * sum_contribution.\n\nFor j=0: incoming is [1]. Sum contribution is PR[1]/outdegree[1] = 0.5 / 1 = 0.5. So new_PR[0] = 0.15 + 0.85*0.5 = 0.15 + 0.425 = 0.575.\n\nFor j=1: incoming is [0]. Sum contribution is PR[0]/outdegree[0} = 0.5 / 1 = 0.5. So new_PR[1] = 0.15 + 0.85*0.5 = 0.575.\n\nSo after first iteration, PR becomes [0.575, 0.575].\n\nWait, but that can't be right because both nodes are symmetric and should have the same PageRank.\n\nBut let's compute again:\n\nPR starts as [0.5, 0.5]\n\nnew_PR[0] = (1 - 0.85)/2 + 0.85 * sum( PR[i]/outdegrees[i] for i in incoming[0] )\n\nincoming[0] is [1], so sum is PR[1]/1 = 0.5.\n\nSo new_PR[0] = 0.15/2? Wait, no: (1 - d)/n is (0.15)/2 = 0.075 for each j?\n\nWait wait, I think I made a mistake earlier. Because in the code above, new_PR is initialized as [(1 -d)/n] * n, which for n=2 would be 0.15/2=0.075 for each j.\n\nSo:\n\nnew_PR[0] = 0.075 + d*(sum_contribution)\n\nsum_contribution for j=0 is PR[1]/outdegree[1} = 0.5 /1 = 0.5\n\nso new_PR[0] = 0.075 + 0.85 * 0.5 = 0.075 + 0.425 = 0.5.\n\nSimilarly, new_PR[1] is the same:\n\nsum_contribution for j=1 is PR[0]/1 = 0.5\n\nnew_PR[1] = 0.075 + 0.85*0.5 = 0.5\n\nSo after first iteration, PR remains [0.5, 0.5]. So convergence occurs immediately.\n\nWait, that seems incorrect because the graph is a cycle, and each node should have equal PageRank.\n\nBut in this case, starting from uniform distribution and damping factor 0.85, why doesn't it change?\n\nBecause both nodes are symmetric, so their contributions remain the same after each iteration.\n\nSo perhaps in such cases, convergence occurs immediately because all nodes have the same value.\n\nWait, but if I set d=1, then what happens? Then PR would be [sum of incoming PR[j]/outdegree[j], ... ] which for j=0: sum is 1/1 = 1. So new_PR[0] = 1, and similarly for j=1, new_PR[1} = 1. But since they are the same, convergence occurs.\n\nWait no: if d=1, then PR would be:\n\nPR(i) = sum_{j->i} PR(j)/outdegree(j)\n\nIn this case, each node points to one other node.\n\nSo for j=0, sum is PR(1)/1. For j=1, sum is PR(0)/1.\n\nThus, PR(0) = PR(1), and solving gives both equal 1/2 each? Wait no:\n\nWait if d=1,\n\nPR(0) = (PR(1))/1\n\nPR(1) = (PR(0))/1\n\nSo substituting: PR(0) = PR(1), but then the equations are identical, so any value would satisfy as long as they are equal. But with initial condition that sum of PR is 2 * 1/2 =1.\n\nWait, no. Wait for d=1, it's a regular equation:\n\nPR(0) = PR(1)\nPR(1) = PR(0)\n\nBut we also have that the total PageRank should be equal to n if d=1? No, actually, when d=1, the sum can be anything because there's no damping term.\n\nWait in our code, with d=1, the new_PR[j] would be 0 (since (1 -d)/n is zero) plus 1 * sum_contribution. So for j=0: sum_contribution = PR(1), and j=1: sum_contribution = PR(0).\n\nSo it's a system:\n\nPR(0) = PR(1)\nPR(1) = PR(0)\n\nWhich again, implies they are equal. But without an initial condition on the sum, any multiple would work.\n\nBut since we're starting from [0.5, 0.5], which is symmetric, it'll stay that way.\n\nSo in our code with d=0.85 and n=2, nodes have equal PageRank of 0.5 each after first iteration because the damping term brings them back to 0.5.\n\nWait no: for j=0:\n\nnew_PR[0] = (1 -d)/n + d * sum_contribution\n\n(1 - 0.85)/2 is 0.15/2=0.075.\n\nsum_contribution is PR[1]/1 =0.5.\n\nSo new_PR[0} = 0.075 + 0.85*0.5 = 0.075 +0.425=0.5.\n\nSimilarly for j=1: same result.\n\nThus, no change after first iteration, so convergence is achieved immediately.\n\nBut wait, in reality, PageRank would assign higher scores to nodes with more incoming links. But in this case, both have the same number of incoming and outgoing links, so they should indeed have the same score.\n\nSo perhaps the code is correct.\n\nAnother test case: a graph where node 0 points to node 1, and node 1 points nowhere (but after adjustment, it points to itself).\n\nn=2, m=1.\n\nEdges: (0,1)\n\noutgoing[0] = [1]\n\noutgoing[1] = [] initially, then adjusted to [1].\n\nincoming[1] = [0], incoming[0] = []\n\nSo outdegrees:\n\noutdegree[0] = 1, outdegree[1} =1.\n\nPR initial: [0.5, 0.5]\n\nFirst iteration:\n\nnew_PR[j=0]: (1 -d)/2 + d * sum_contribution.\n\nincoming[0] is empty, so sum_contribution is zero. So new_PR[0} = (1 -d)/2 = 0.075.\n\nj=1: incoming is [0]. sum_contribution is PR[0}/1 =0.5.\n\nnew_PR[1} = 0.075 + d * 0.5 = 0.075 +0.425=0.5.\n\nSo new_PR is [0.075, 0.5]\n\nCompare to PR: [0.5, 0.5]. Max difference is 0.425 > epsilon.\n\nSecond iteration:\n\nnew_PR[0} = (1 -d)/2 + d * sum_contribution.\n\nsum_contribution for j=0 is zero because incoming is empty.\n\nso new_PR[0}=0.075.\n\nfor j=1: sum_contribution is PR[0}/1 = 0.075.\n\nso new_PR[1} = 0.075 + d *0.075 = 0.075 +0.06375=0.13875\n\nSo new_PR is [0.075, 0.13875]\n\nCompare to previous PR: [0.075, 0.5]. Difference for j=1 is |0.5 - 0.13875|=0.36125>epsilon.\n\nThird iteration:\n\nj=0: new_PR[0}=0.075 + d*0 =0.075\n\nj=1: sum_contribution is PR[0}/1=0.075, so new_PR[1} = 0.075 +d *0.075=0.075+0.06375=0.13875.\n\nWait no—PR in previous step was [0.075, 0.13875], so for j=1:\n\nsum_contribution is PR[0} which is 0.075.\n\nThus, new_PR[j=1}=0.075 +d*0.075=0.075+0.06375=0.13875\n\nWait same as before? Hmm.\n\nWait no—wait, the sum_contribution for j=1 is based on PR[0} from previous step which was 0.075. So new_PR[j=1}=0.075 + d *0.075= 0.13875\n\nBut in this iteration, the PR for j=1 doesn't change. Hmm, but that can't be right because the value is decreasing.\n\nWait maybe I made a mistake.\n\nWait no, initial PR after first iteration was [0.075, 0.5]\n\nSecond iteration: new_PR[0}=0.075 (since sum_contribution for j=0 is zero).\n\nnew_PR[j=1} = 0.075 + d * (PR[0}/outdegree[0}) =0.075 + 0.85*0.075=0.075+0.06375=0.13875.\n\nSo PR after second iteration is [0.075, 0.13875]\n\nThird iteration:\n\nsum_contribution for j=0: zero.\n\nnew_PR[0}=0.075\n\nsum_contribution for j=1}: PR[0}/1=0.075.\n\nso new_PR[j=1} =0.075 + 0.85*0.075=0.075+0.06375=0.13875\n\nSo no change in j=1.\n\nWait, so the value is stuck at 0.13875 for j=1? That can't be right because it's decreasing each time.\n\nWait I think perhaps I'm miscalculating.\n\nAlternatively, maybe this graph converges to a fixed point where node 0 has PageRank (1 -d)/n + d * sum_{j->i} PR(j)/outdegree(j)\n\nIn this case:\n\nPR(0) = (1 -d)/2 + d*(sum from j=0's incoming links). But j=0 has no incoming links, so PR(0}= (1-d)/2.\n\nSimilarly, PR(1)= (1 -d)/2 + d*(PR(0}/outdegree[0}) )\n\nWhich is:\n\nPR(1} = 0.075 + d * PR(0}\n\nBut since PR(0}=0.075,\n\nthen PR(1}=0.075 +0.85*0.075=0.075+0.06375=0.13875.\n\nThus, this is the fixed point.\n\nSo in our code, after second iteration, the values are [0.075, 0.13875]\n\nThird iteration:\n\nPR remains same because for j=1, sum_contribution is PR[0}=0.075 which when multiplied by d gives 0.06375, added to 0.075.\n\nThus, it's a fixed point.\n\nSo the code correctly converges after two iterations.\n\nThus, seems correct.\n\nAnother test case: a graph with three nodes where node 0 points to 1 and 2; node 1 points to 2; node 2 points to itself.\n\nn=3, m=4 edges: 0->1, 0->2, 1->2, 2->2.\n\noutgoing:\n\nnode 0: outdegree 2\n\nnode 1: outdegree 1\n\nnode 2: outdegree 1 (only pointing to self).\n\nincoming:\n\nnode 1: incoming from 0\n\nnode 2: incoming from 0 and 1 and itself.\n\nBut for PageRank, we ignore self loops? Or do they count?\n\nIn our code, when building the adjacency list, each node's outgoing edges are considered. So if a node points to itself, it counts as an edge.\n\nThus, in this case:\n\noutgoing[0] = [1,2]\n\noutgoing[1}=[2}\n\noutgoing[2}=[2}\n\nincoming:\n\nnode 0: none\n\nnode 1: from 0\n\nnode 2: from 0,1,2.\n\nBut when building the PageRank, we only consider incoming edges, regardless of being self loops or not.\n\nSo initial PR is [1/3, 1/3, 1/3}.\n\nAfter first iteration:\n\nCompute new_PR[j] for each j.\n\nj=0: incoming none. So sum_contribution =0. new_PR[0}= (1 -d)/n + d *0= 0.15/3=0.05.\n\nWait wait, n is 3.\n\n(1 -d)/n = (0.15)/3=0.05.\n\nSo:\n\nj=0: sum_contribution=0 -> new_PR[0}=0.05\n\nj=1: incoming from 0. So sum_contribution= PR[0}/outdegree[0} = (1/3)/2= 1/(6)=0.1667.\n\nnew_PR[j=1}=0.05 + d * 0.1667=0.05+0.85*0.1667≈0.05 +0.1414=0.1914\n\nj=2: incoming from 0,1,2.\n\nsum_contribution = PR[0}/2 (since outdegree of 0 is 2) + PR[1}/1 + PR[2}/1\n\nWait no:\n\nFor j=2, the sum is over all i where i points to j.\n\nEach term is PR[i]/outdegree[i}.\n\nSo for i=0: PR[0}=1/3 divided by outdegree[0}=2 → (1/3)/2= 1/6 ≈0.1667\n\ni=1: PR[1}=1/3 divided by outdegree[1}=1 →1/3≈0.3333\n\ni=2: PR[2}=1/3 divided by outdegree[2}=1→1/3≈0.3333.\n\nSo sum_contribution for j=2 is 0.1667 + 0.3333 + 0.3333 ≈0.8333\n\nThus, new_PR[j=2} = (1 -d)/n + d * sum_contribution → 0.05 + 0.85*0.8333≈0.05+0.7083≈0.7583.\n\nSo after first iteration:\n\nPR is [0.05, 0.1914, 0.7583]\n\nNow compute next iteration.\n\nCompute new_PR[j=0} = (1 -d)/n + sum of PR[i}/outdegree[i} where i points to j.\n\nBut for j=0, no incoming edges except perhaps none.\n\nWait in our graph, only node 0 points to others, but nobody points back to 0. So sum_contribution is zero. Thus:\n\nnew_PR[0}=0.05\n\nj=1: incoming from 0. So i=0.\n\nsum_contribution = PR[0}/outdegree[0} →0.05/2=0.025.\n\nThus, new_PR[j=1}=0.05 + d *0.025=0.05 +0.85*0.025≈0.05+0.0213=0.0713\n\nj=2: sum_contribution is:\n\ni=0: PR[0}/2 →0.05/2=0.025.\n\ni=1: PR[1}=0.1914 / outdegree[1}=1→0.1914.\n\ni=2: PR[j=2}=0.7583 /1→0.7583.\n\nsum_contribution ≈0.025 + 0.1914 +0.7583≈0.9747\n\nnew_PR[j=2} =0.05 +0.85*0.9747≈0.05+0.830≈0.88.\n\nSo after second iteration, PR is [0.05, 0.0713, 0.88].\n\nThird iteration:\n\nj=0: new_PR[0}=0.05\n\nj=1: sum_contribution =PR[0}/2 →0.05/2=0.025.\n\nnew_PR[j=1} =0.05 +0.85*0.025≈0.05+0.0213=0.0713.\n\nSame as previous step.\n\nj=2: sum_contribution:\n\ni=0: 0.05/2=0.025\n\ni=1:0.0713/1=0.0713\n\ni=2:0.88 /1=0.88\n\nsum≈0.025+0.0713+0.88≈0.9763\n\nnew_PR[j=2}=0.05 +0.85*0.9763≈0.05 + 0.8349≈0.8849.\n\nSo after third iteration: [0.05, 0.0713, 0.8849]\n\nFourth iteration:\n\nj=0: same as before →0.05\n\nj=1: sum_contribution =PR[0}/2=0.05/2=0.025.\n\nnew_PR[j=1}=0.05 +0.85*0.025≈0.0713\n\nSame as before.\n\nj=2: sum_contribution:\n\ni=0: 0.05/2=0.025\n\ni=1:0.0713 /1=0.0713\n\ni=2:0.8849/1=0.8849.\n\nsum≈0.025+0.0713+0.8849≈0.9812\n\nnew_PR[j=2}=0.05 +0.85*0.9812≈0.05 + 0.8389≈0.8889.\n\nSo it's converging towards j=2 having about 0.89, others around 0.05 and ~0.07.\n\nThis seems reasonable given the structure: node 2 is pointed to by everyone, so it has highest PR.\n\nThus, the code should correctly compute this.\n\nIn terms of implementation:\n\nWe can represent the graph as an adjacency list where each node points to a list of nodes it connects to.\n\nThen, for each iteration, we calculate the new_PR based on the current PR values.\n\nThe algorithm is:\n\n1. Read input: number of nodes, edges.\n\n2. Build adjacency list.\n\n3. Initialize PR vector with 1/n for each node.\n\n4. Iterate until convergence or max iterations:\n\n   a. For each node j, compute sum_contribution = sum over i where i points to j of (PR[i] / outdegree[i])\n\n   b. new_PR[j] = (1 - d) / n + d * sum_contribution\n\n5. After convergence, output PR values.\n\nIn the code:\n\n- We can represent the graph as a list of lists: adj_list[i] contains all nodes that i points to.\n\nWait no: for PageRank, we need to know which nodes point to j, not where i points to.\n\nSo in our sum_contribution step, we need to iterate over all i that have an edge pointing to j. So the adjacency list should be built such that for each node i, adj_list[i] contains nodes it points to. Then, for a given j, its incoming edges are all i where j is in adj_list[i].\n\nBut this can be computationally expensive if we need to check for each j which i's have j in their adjacency list.\n\nAlternatively, perhaps the more efficient way is to build an inverse adjacency list: inv_adj[j] contains all i that point to j. Then sum_contribution for j is sum of PR[i]/outdegree[i} for i in inv_adj[j].\n\nSo during building the graph:\n\n- For each edge u -> v, add u to inv_adj[v].\n\nThus, for each j, inv_adj[j] gives all nodes pointing to j.\n\nThis way, when calculating sum_contribution for j, we can quickly get all i's that point to j by looking up inv_adj[j}.\n\nYes, this is a better approach.\n\nSo the steps:\n\n1. Read n and m.\n\n2. Initialize adj_list as [[] for _ in range(n)] (adjacency list where each node points to its outgoing nodes)\n\n3. Initialize inv_adj as [[] for _ in range(n)] (inverse adjacency list where each j has list of i's pointing to it)\n\n4. For each edge u->v:\n\n   a. append v to adj_list[u]\n\n   b. append u to inv_adj[v}\n\n5. Compute outdegree for each node: outdegree[i} = len(adj_list[i})\n\n6. Initialize PR vector as [1/n] * n.\n\n7. Set damping factor d (usually 0.85)\n\n8. Iterate until convergence:\n\n   a. compute new_PR[j} = (1 -d)/n + d * sum(PR[i]/outdegree[i} for i in inv_adj[j})\n\n   b. check if the difference between new_PR and PR is below threshold.\n\n   c. update PR to new_PR.\n\nThus, code can be written accordingly.\n\nNow, write the Python code:\n\nRead n and m from input.\n\nBuild adj_list and inv_adj.\n\nCompute outdegree for each node.\n\nInitialize PR.\n\nSet d=0.85.\n\nSet threshold for convergence, say 1e-6.\n\nIterate until convergence or max iterations (say 100 times).\n\nAt each step:\n\n   compute new_PR as per formula.\n\n   compare with previous PR to see if converged.\n\nThus, code outline:\n\nn = int(input().split()[0]) # Wait no: first line is n m.\n\nWait, the input will be given as follows:\n\nFirst line: n and m.\n\nThen next m lines: each edge u v.\n\nSo in Python:\n\nimport sys\n\nfrom sys import stdin\n\nn, m = map(int, stdin.readline().split())\n\nadj_list = [[] for _ in range(n)]\n\ninv_adj = [[] for _ in range(n)]\n\nfor _ in range(m):\n\n    u, v = map(int, stdin.readline().split())\n\n    adj_list[u].append(v)\n\n    inv_adj[v].append(u)\n\noutdegree = [len(lst) for lst in adj_list]\n\nd = 0.85\n\nPR = [1 / n] * n\n\nthreshold = 1e-6\n\nmax_iterations = 100\n\nfor it in range(max_iterations):\n\n    new_PR = [ (1 - d)/n + d*sum( PR[i]/outdegree[i] for i in inv_adj[j]) for j in range(n) ]\n\n    # compute difference between new_PR and PR.\n\n    diff = max(abs(new_PR[j] - PR[j}) for j in range(n))\n\n    if diff < threshold:\n\n        break\n\n    PR = new_PR.copy()\n\nprint(PR)\n\nWait, but in Python, the list comprehensions are evaluated each time. So perhaps we can compute it efficiently.\n\nBut for small n, this is acceptable.\n\nAlso, when a node has outdegree zero (possible?), then division by zero could occur. But since nodes with no outgoing edges will contribute nothing to others except themselves? Or is that handled?\n\nWait, in PageRank, if a node has no outgoing edges, it contributes its entire PR to itself in the next iteration.\n\nBut in our code, if outdegree[i} is zero, then when we compute sum(PR[i}/outdegree[i}), this will be division by zero. So perhaps we need to handle nodes with outdegree zero.\n\nIn practice, such nodes are considered to have a self-loop for the purposes of computation.\n\nSo how?\n\nWe can modify the code so that if outdegree[i} is zero, then when computing PR[i}/outdegree[i}, it's treated as infinity or something. But in reality, during iteration, all nodes must have at least one outgoing edge because otherwise, their contribution to others would be undefined.\n\nWait no: a node with no outgoing edges can exist. For example, if the graph is disconnected.\n\nIn such cases, when computing sum_contribution for j, any i that points to j and has outdegree zero will contribute PR[i} /0 which is infinite, but in reality, nodes with no outgoing edges are considered to have a self-loop, meaning their entire PageRank remains within themselves.\n\nThus, perhaps the correct approach is:\n\nWhen a node i has outdegree 0, then its contribution to others is zero because it doesn't point anywhere else except itself (but we don't model that here). Wait, but in our code, if i points to j, and i's outdegree is zero, this can't be. Because for an edge u->v, u must have at least one outgoing edge.\n\nWait no: the edge exists, so adj_list[u] has v, meaning u has at least one outgoing edge. So in our code, nodes with no outgoing edges cannot receive any incoming edges because if a node i has no outgoing edges, it can't be in any adjacency list except its own.\n\nThus, when building inv_adj, for j, all i's in inv_adj[j} have at least one outgoing edge (since the edge u->v implies u is in adj_list[u], which has v). So outdegree[i} >=1, because i points to v. Therefore, division by zero can't happen.\n\nThus, no problem with division by zero.\n\nWait, but if a node has no outgoing edges, it's possible that it doesn't point to anyone else except itself? Or perhaps in the code, such nodes are not part of any edge, so their outdegree is zero. But then, when computing sum_contribution for j, since i can only be those who have an edge to j, but if i has no outgoing edges, that's impossible because adj_list[i} must contain at least one node (j), which would make outdegree[i} >=1.\n\nWait no: If a node i points to j, then adj_list[i}.append(j) => len(adj_list[i}) is at least 1. So for any i in inv_adj[j}, adj_list[i} has at least one element, so outdegree[i} is >=1.\n\nThus, the code should be safe.\n\nTesting with sample input:\n\nSample Input 1:\n\n4 5\n\n0 1\n\n1 2\n\n2 3\n\n3 0\n\n0 3\n\nSo n=4, m=5 edges.\n\nEdges are: 0->1; 1->2; 2->3; 3->0; 0->3.\n\nAdj_list:\n\n0: [1,3]\n\n1: [2]\n\n2: [3]\n\n3: [0]\n\ninv_adj:\n\nCompute for each j, which i's point to it.\n\nj=0: i=3 (from edge 3->0), and also any others? Wait no, the edges are u->v. So inv_adj[v].append(u).\n\nSo for edge 0->1: v is 1, so inv_adj[1] appends 0.\n\nEdge 1->2: inv_adj[2} appends 1.\n\nEdge 2->3: inv_adj[3} appends 2.\n\nEdge 3->0: inv_adj[0} appends 3.\n\nEdge 0->3: inv_adj[3} appends 0.\n\nThus, inv_adj is:\n\ninv_adj[0] = [3]\n\ninv_adj[1] = [0]\n\ninv_adj[2] = [1]\n\ninv_adj[3] = [2,0]\n\noutdegree:\n\nnode 0: 2\n\nnode 1:1\n\nnode 2:1\n\nnode3:1.\n\nPR starts as [0.25, 0.25, 0.25, 0.25].\n\nCompute new_PR[j} for each j.\n\nFor j=0:\n\nsum = sum( PR[i]/outdegree[i} for i in inv_adj[0} )\n\ninv_adj[0} is [3]\n\nso PR[3}/1 => 0.25/1=0.25\n\nnew_PR[0} = (1-0.85)/4 + 0.85 * 0.25 = 0.0625 + 0.2125 = 0.275.\n\nSimilarly for j=1:\n\ninv_adj[1} is [0]\n\nPR[0}/2: 0.25/2=0.125\n\nnew_PR[1}= (0.0625) + 0.85 * 0.125 = 0.0625 + 0.10625 = 0.16875.\n\nj=2:\n\ninv_adj is [1}\n\nPR[1}/1: 0.25/1=0.25\n\nnew_PR[j}=0.0625 + 0.85 *0.25= 0.0625+0.2125=0.275.\n\nj=3:\n\ninv_adj is [2,0}\n\nPR[2}/1 =0.25\n\nPR[0}/2=0.125\n\nsum: 0.25 + 0.125 = 0.375\n\nnew_PR[j}=0.0625 + 0.85 * 0.375 = 0.0625 + 0.31875=0.38125.\n\nSo new_PR is:\n\n[0.275, 0.16875, 0.275, 0.38125]\n\nCompute the difference between PR and new_PR: max diffs are 0.275-0.25=0.025.\n\nWhich is larger than threshold 1e-6, so continue.\n\nNext iteration:\n\nPR = [0.275, 0.16875, 0.275, 0.38125]\n\nCompute new_PR[j} for each j.\n\nj=0: inv_adj[0}= [3}\n\nPR[3}/outdegree[3}=0.38125/1 = 0.38125\n\nnew_PR[0} = 0.0625 + 0.85 *0.38125= 0.0625 + 0.3240625= 0.3865625.\n\nj=1: inv_adj is [0}\n\nPR[0}/2 =0.275/2=0.1375\n\nnew_PR[j}=0.0625 + 0.85*0.1375 =0.0625+0.116875=0.179375.\n\nj=2: inv_adj[2}=[1}\n\nPR[1}/outdegree[1}=0.16875/1=0.16875\n\nnew_PR[j}=0.0625 + 0.85*0.16875 =0.0625+0.1434375=0.2059375.\n\nj=3: inv_adj is [2,0}\n\nPR[2}/1=0.275\n\nPR[0}/2=0.275/2=0.1375\n\nsum= 0.275 + 0.1375 =0.4125\n\nnew_PR[j}=0.0625 + 0.85*0.4125= 0.0625+0.349375= 0.411875.\n\nSo new_PR is [0.3865625, 0.179375, 0.2059375, 0.411875]\n\nCompute differences: max difference between previous and current:\n\nj=0: 0.3865625 - 0.275 = 0.1115625\n\nSo still larger than threshold.\n\nContinue until convergence.\n\nBut this is tedious to compute manually, but the code should correctly handle it.\n\nThus, the Python code as written above should work.\n</think>\n\nTo solve this problem, we need to compute the PageRank values for nodes in a directed graph. PageRank is an algorithm used by Google Search to determine the relative importance of web pages. The idea behind PageRank is that more important web pages are linked to by other important web pages.\n\n### Approach\n1. **Graph Representation**: Represent the graph using an adjacency list and an inverse adjacency list. The adjacency list keeps track of outgoing edges from each node, while the inverse adjacency list helps in quickly finding all nodes pointing to a given node.\n2. **Initialization**: Initialize the PageRank (PR) vector with equal values for all nodes, as initially, we assume all nodes have equal importance.\n3. **Iteration**: Iterate until convergence or a maximum number of iterations is reached. In each iteration:\n   - Compute the new PR values using the formula: \n     \\[\n     \\text{new\\_PR}[j] = (1 - d) / n + d * \\sum(\\text{PR}[i] / \\text{outdegree}[i]) \\quad \\text{for all } i \\text{ pointing to } j\n     \\]\n   - Check if the difference between the new PR values and the previous PR values is below a threshold to determine convergence.\n4. **Damping Factor**: Use a damping factor (typically 0.85) to simulate user behavior where they might stop clicking after some pages.\n\n### Solution Code\n```python\nimport sys\n\ndef main():\n    # Read input\n    n, m = map(int, sys.stdin.readline().split())\n    \n    adj_list = [[] for _ in range(n)]\n    inv_adj = [[] for _ in range(n)]\n    \n    for _ in range(m):\n        u, v = map(int, sys.stdin.readline().split())\n        adj_list[u].append(v)\n        inv_adj[v].append(u)\n    \n    outdegree = [len(lst) for lst in adj_list]\n    d = 0.85\n    PR = [1.0 / n] * n\n    \n    threshold = 1e-6\n    max_iterations = 1000\n    iter = 0\n    \n    while iter < max_iterations:\n        new_PR = [0.0] * n\n        for j in range(n):\n            sum_val = 0.0\n            for i in inv_adj[j]:\n                sum_val += PR[i] / outdegree[i]\n            new_PR[j] = (1 - d) / n + d * sum_val\n        \n        # Check for convergence\n        max_diff = max(abs(new_PR[j] - PR[j]) for j in range(n))\n        if max_diff < threshold:\n            break\n        \n        PR = new_PR.copy()\n        iter += 1\n    \n    print(\"PageRank values after convergence:\")\n    for i in range(n):\n        print(f\"Node {i}: {PR[i]:.8f}\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\n### Explanation\n- **Graph Representation**: The graph is represented using two lists: `adj_list` for outgoing edges and `inv_adj` for incoming edges.\n- **Initialization**: Each node starts with an equal PageRank value of \\(1/n\\).\n- **Iteration Process**: In each iteration, the new PageRank for each node is calculated based on the sum of contributions from all nodes pointing to it, scaled by their respective outdegrees and adjusted using the damping factor.\n- **Convergence Check**: The process stops early if the changes in PageRank values fall below a specified threshold, ensuring efficiency.\n\nThis approach efficiently computes the PageRank values using an iterative method, ensuring that we only continue until either convergence is achieved or a maximum number of iterations is reached."
        }
      ],
      "system_messages": []
    }
  },
  "current_chat": "Чат 1"
}