import streamlit as st
from llama_index.core import SimpleDirectoryReader, PromptTemplate
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
import qdrant_client
from llama_index.vector_stores.qdrant import QdrantVectorStore
from llama_index.core.storage.storage_context import StorageContext
from llama_index.core.indices.vector_store.base import VectorStoreIndex
from llama_index.llms.ollama import Ollama
from llama_index.core.llms import ChatMessage
import re
import json
from pathlib import Path

# ======= –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ========
input_dir_path = "C:\RAG\Knowledge base"
collection_name = "chat_with_docs"
# –£–¥–∞–ª—è–µ–º –º–æ–¥–µ–ª—å –¥–ª—è HuggingFace API ‚Äì –æ—Å—Ç–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª–∏ –¥–ª—è Ollama
available_models = {
    "deepseek-r1:14b": "deepseek-r1:14b",
    "deepseek-r1-abliterated:14b": "huihui_ai/deepseek-r1-abliterated:14b"
}
HISTORY_FILE = Path("chat_history.json")

# ======= –§—É–Ω–∫—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã —Å –∏—Å—Ç–æ—Ä–∏–µ–π ========
def load_chat_history():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞"""
    try:
        if HISTORY_FILE.exists():
            with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
                converted_chats = {}
                for chat_name, content in data["chats"].items():
                    if isinstance(content, list):  # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç
                        converted_chats[chat_name] = {
                            "messages": content,
                            "system_messages": []
                        }
                    else:  # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç
                        converted_chats[chat_name] = content
                
                st.session_state.chats = converted_chats
                st.session_state.current_chat = data["current_chat"]
                
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏: {str(e)}")
        st.session_state.chats = {
            "–ß–∞—Ç 1": {
                "messages": [],
                "system_messages": []
            }
        }
        st.session_state.current_chat = "–ß–∞—Ç 1"

def save_chat_history():
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª"""
    try:
        data = {
            "chats": st.session_state.chats,
            "current_chat": st.session_state.current_chat
        }
        with open(HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏: {str(e)}")

# ======= –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ ========
if "model_name" not in st.session_state:
    st.session_state.model_name = "deepseek-r1:14b"
if "temperature" not in st.session_state:  # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É
    st.session_state.temperature = 0.6  # 0.6 - —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ deepseek-r1

@st.cache_resource(show_spinner=False)
def initialize_rag_components(model_name, temperature):
    try:
        # –¢–æ–ª—å–∫–æ –ª–æ–≥–∏–∫–∞ –±–µ–∑ Streamlit —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        loader = SimpleDirectoryReader(
            input_dir=input_dir_path,
            required_exts=[".pdf"],
            recursive=True
        )
        docs = loader.load_data()
        
        if len(docs) == 0:
            raise ValueError("–í –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –Ω–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤!")

        embed_model = HuggingFaceEmbedding(
            model_name="Snowflake/snowflake-arctic-embed-m",
            trust_remote_code=True
        )

        client = qdrant_client.QdrantClient(
            host="localhost",
            port=6333
        )

        vector_store = QdrantVectorStore(
            client=client,
            collection_name=collection_name
        )

        storage_context = StorageContext.from_defaults(vector_store=vector_store)
        index = VectorStoreIndex(
            docs,
            embed_model=embed_model,
            storage_context=storage_context
        )

        query_engine = index.as_query_engine(
            similarity_top_k=10, 
            llm=initialize_llm(model_name, temperature),
            streaming=True,  # –í–∫–ª—é—á–∞–µ–º –ø–æ—Ç–æ–∫–æ–≤—ã–π —Ä–µ–∂–∏–º
            response_mode="compact"  # –ò–ª–∏ "tree_summarize" –¥–ª—è –ª—É—á—à–µ–π –ø–æ—Ç–æ–∫–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        )
        
        qa_prompt_tmpl_str = """
        You are an AI assistant specialized in answering user queries based on the provided context. 
        If the answer is within the given context, provide a concise and accurate response.
        If the answer is not in the context, state that you don't know instead of making up information.

        ### Context:
        {context}

        ### Question:
        {question}

        ### Answer:
        """

        qa_prompt_tmpl = PromptTemplate(qa_prompt_tmpl_str)
        query_engine.update_prompts({"response_synthesizer:text_qa_template": qa_prompt_tmpl})
        
        return {
            "query_engine": query_engine,
            "docs_count": len(docs),
            "embed_model": "Snowflake/snowflake-arctic-embed-m",
            "llm_model": model_name
        }
            
    except Exception as e:
        raise RuntimeError(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ RAG: {str(e)}")

@st.cache_resource(show_spinner=False)
def initialize_llm(model_name, temperature):
    try:
        # –¢–µ–ø–µ—Ä—å –≤—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º Ollama
        return Ollama(
            model=model_name,
            temperature=temperature,
            request_timeout=300.0
        )
    except Exception as e:
        raise e

# ======= –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ========
st.set_page_config(
    page_title="Multi-Mode Chat",
    page_icon="ü§ñ",
    layout="centered"
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏
if "chats" not in st.session_state:
    load_chat_history()  # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ

# –ö–∞—Å—Ç–æ–º–Ω—ã–µ —Å—Ç–∏–ª–∏
st.markdown("""
    <style>
    .stTextArea textarea {
        min-height: 100px !important;
        max-height: 200px !important;
    }
    .chat-list {
        max-height: 70vh;
        overflow-y: auto;
    }
    </style>
""", unsafe_allow_html=True)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏
if "chats" not in st.session_state:
    st.session_state.chats = {
        "–ß–∞—Ç 1": {"messages": [], "system_messages": []}
    }

if "current_chat" not in st.session_state:
    st.session_state.current_chat = "–ß–∞—Ç 1"

if "processing" not in st.session_state:
    st.session_state.processing = False

if "mode" not in st.session_state:
    st.session_state.mode = "–û–±—ã—á–Ω—ã–π —á–∞—Ç"

# ======= –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ ========
with st.sidebar:
    st.title("‚ö° –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–æ–≤")
    
    if st.button("üÜï –ù–æ–≤—ã–π —á–∞—Ç"):
        new_chat_number = len(st.session_state.chats) + 1
        new_chat_name = f"–ß–∞—Ç {new_chat_number}"
        while new_chat_name in st.session_state.chats:
            new_chat_number += 1
            new_chat_name = f"–ß–∞—Ç {new_chat_number}"
        st.session_state.chats[new_chat_name] = {"messages": [], "system_messages": []}
        st.session_state.current_chat = new_chat_name
        save_chat_history()
        st.rerun()
    
    st.markdown('<div class="chat-list">', unsafe_allow_html=True)
    for chat_name in list(st.session_state.chats.keys()):
        if st.session_state.get("editing_chat") == chat_name:
            new_name = st.text_input(
                "–ù–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ:",
                value=chat_name,
                key=f"edit_{chat_name}",
                label_visibility="collapsed",
                on_change=lambda: st.session_state.update({"text_input_edited": True})
            )
            
            if "text_input_edited" in st.session_state:
                if new_name and new_name != chat_name:
                    if new_name not in st.session_state.chats:
                        st.session_state.chats[new_name] = st.session_state.chats.pop(chat_name)
                        if chat_name == st.session_state.current_chat:
                            st.session_state.current_chat = new_name
                        del st.session_state.editing_chat
                        del st.session_state.text_input_edited
                        save_chat_history()
                        st.rerun()
                    else:
                        st.error("–ù–∞–∑–≤–∞–Ω–∏–µ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç!")
                del st.session_state.text_input_edited
            
            cols = st.columns([6, 5, 1])
            with cols[0]:
                if st.button("‚úÖ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å", key=f"save_{chat_name}"):
                    if new_name and new_name != chat_name:
                        if new_name not in st.session_state.chats:
                            st.session_state.chats[new_name] = st.session_state.chats.pop(chat_name)
                            if chat_name == st.session_state.current_chat:
                                st.session_state.current_chat = new_name
                            del st.session_state.editing_chat
                            st.rerun()
                        else:
                            st.error("–ù–∞–∑–≤–∞–Ω–∏–µ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç!")
            with cols[1]:
                if st.button("‚ùå –û—Ç–º–µ–Ω–∞", key=f"cancel_{chat_name}"):
                    del st.session_state.editing_chat
                    if "text_input_edited" in st.session_state:
                        del st.session_state.text_input_edited
                    st.rerun()
        
        else:
            cols = st.columns([9, 2, 2])
            with cols[0]:
                is_active = chat_name == st.session_state.current_chat
                btn_type = "primary" if is_active else "secondary"
                
                if st.button(
                    chat_name,
                    key=f"btn_{chat_name}",
                    use_container_width=True,
                    type=btn_type
                ):
                    if is_active:
                        st.session_state.editing_chat = chat_name
                    else:
                        st.session_state.current_chat = chat_name
                    st.rerun()
            
            with cols[1]:
                if st.button("‚úèÔ∏è", key=f"edit_btn_{chat_name}", help="–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å —á–∞—Ç"):
                    st.session_state.editing_chat = chat_name
                    st.rerun()
            
            with cols[2]:
                if st.button("üóëÔ∏è", key=f"del_{chat_name}", help="–£–¥–∞–ª–∏—Ç—å —á–∞—Ç"):
                    if len(st.session_state.chats) > 1:
                        del st.session_state.chats[chat_name]
                        if chat_name == st.session_state.current_chat:
                            st.session_state.current_chat = next(iter(st.session_state.chats))
                        save_chat_history()
                        st.rerun()
                    else:
                        st.toast("–ù–µ–ª—å–∑—è —É–¥–∞–ª–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Ç!", icon="‚ùå")

    st.markdown('</div>', unsafe_allow_html=True)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    st.title("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    # –í–∏–¥–∂–µ—Ç –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏ ‚Äì –æ–ø—Ü–∏—è HuggingFace —É–¥–∞–ª–µ–Ω–∞
    current_model_key = [k for k, v in available_models.items() if v == st.session_state.model_name][0]
    new_model_key = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
        options=list(available_models.keys()),
        index=list(available_models.keys()).index(current_model_key),
        key="model_selector"
    )
    if available_models[new_model_key] != st.session_state.model_name:
        st.session_state.model_name = available_models[new_model_key]
        st.toast(f"–ú–æ–¥–µ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞: {new_model_key}", icon="‚ÑπÔ∏è")
        initialize_rag_components.clear()
        initialize_llm.clear()
        st.session_state.llm = initialize_llm(st.session_state.model_name, st.session_state.temperature)
        st.rerun()
    
    new_temp = st.slider(
        "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:",
        min_value=0.1,
        max_value=1.0,
        value=st.session_state.temperature,
        step=0.1,
        help="–ß–µ–º –≤—ã—à–µ –∑–Ω–∞—á–µ–Ω–∏–µ ‚Äî —Ç–µ–º –∫—Ä–µ–∞—Ç–∏–≤–Ω–µ–µ –æ—Ç–≤–µ—Ç—ã. –ù–∏–∂–µ ‚Äî –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ –∏ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ."
    )
    
    if new_temp != st.session_state.temperature:
        st.session_state.temperature = new_temp
        st.toast(f"–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞: {new_temp}", icon="üå°Ô∏è")
        initialize_llm.clear()
        st.session_state.llm = initialize_llm(st.session_state.model_name, st.session_state.temperature)
        st.rerun()

    new_mode = st.radio(
        "–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã:",
        ["RAG", "–û–±—ã—á–Ω—ã–π —á–∞—Ç"],
        index=0 if st.session_state.mode == "RAG" else 1
    )
    
    if new_mode != st.session_state.mode:
        st.session_state.mode = new_mode
        st.session_state.chats[st.session_state.current_chat]["messages"] = []
        st.rerun()

    if st.session_state.mode == "RAG":
        try:
            if "rag_info" not in st.session_state:
                with st.status("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã...") as status:
                    st.write("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
                    st.session_state.rag_info = initialize_rag_components(st.session_state.model_name, st.session_state.temperature)
                    status.update(label="‚úÖ RAG —Å–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞", state="complete")
                    st.toast("RAG —Å–∏—Å—Ç–µ–º–∞ —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞!", icon="üéâ")
            
            st.subheader("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã RAG")
            st.write(f"**–ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤:**\n{st.session_state.rag_info['embed_model']}")
            st.write(f"**–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ:**\n{st.session_state.rag_info['docs_count']}")
            st.write(f"**–Ø–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å:**\n{st.session_state.rag_info['llm_model']}")
            st.write(f"**–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏:** {st.session_state.temperature}")
            st.write(f"**–í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î:**\nQdrant ({collection_name})")
            
        except Exception as e:
            st.error(str(e))
            st.stop()
    else:
        try:
            if "llm" not in st.session_state:
                with st.spinner(f"–ó–∞–≥—Ä—É–∑–∫–∞ {st.session_state.model_name}..."):
                    st.session_state.llm = initialize_llm(st.session_state.model_name, st.session_state.temperature)
                    st.toast(f"‚úÖ {st.session_state.model_name} –∑–∞–≥—Ä—É–∂–µ–Ω–∞", icon="üéâ")
            
            st.subheader("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —á–∞—Ç–∞")
            st.write(f"**–†–µ–∂–∏–º:** –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —á–∞—Ç")
            st.write(f"**–ú–æ–¥–µ–ª—å:** {st.session_state.model_name}")
            st.write(f"**–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞:** {st.session_state.temperature}")
            st.warning("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–µ–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {str(e)}")
            st.stop()

    st.title("‚öôÔ∏è –°–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è —á–∞—Ç–∞")
    
    current_system_messages = st.session_state.chats[st.session_state.current_chat]["system_messages"]
    
    for idx, sm in enumerate(current_system_messages):
        cols = st.columns([0.8, 0.2])
        with cols[0]:
            st.info(sm)
        with cols[1]:
            if st.button("üóëÔ∏è", key=f"del_sm_{idx}"):
                st.session_state.chats[st.session_state.current_chat]["system_messages"].pop(idx)
                save_chat_history()
                st.rerun()
    
    if st.button("‚ûï –î–æ–±–∞–≤–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"):
        st.session_state.adding_sm = True
    
    if st.session_state.get("adding_sm"):
        with st.form(key="add_sm_form"):
            new_sm = st.text_area("–°–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —á–∞—Ç–∞:")
            cols = st.columns(2)
            with cols[0]:
                if st.form_submit_button("–î–æ–±–∞–≤–∏—Ç—å"):
                    if new_sm.strip():
                        st.session_state.chats[st.session_state.current_chat]["system_messages"].append(new_sm.strip())
                        save_chat_history()
                        st.session_state.adding_sm = False
                        st.rerun()
            with cols[1]:
                if st.form_submit_button("–û—Ç–º–µ–Ω–∞"):
                    st.session_state.adding_sm = False
                    st.rerun()

# ======= –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å ========
st.title("üí¨ Multi-Mode Chat Assistant")

chat_container = st.container()
with chat_container:
    for i, msg in enumerate(st.session_state.chats[st.session_state.current_chat]["messages"]):
        with st.chat_message(msg["role"], avatar="üë§" if msg["role"] == "user" else "ü§ñ"):
            if st.session_state.get("editing_index") == i and msg["role"] == "user":
                with st.form(key=f"edit_form_{i}"):
                    edited_msg = st.text_area(
                        "–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ",
                        value=msg["content"],
                        key=f"edit_input_{i}",
                        height=100
                    )
                    
                    cols = st.columns([3, 1, 1])
                    with cols[0]:
                        if st.form_submit_button("‚úÖ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å"):
                            st.session_state.chats[st.session_state.current_chat]["messages"][i]["content"] = edited_msg
                            st.session_state.chats[st.session_state.current_chat]["messages"] = st.session_state.chats[st.session_state.current_chat]["messages"][:i+1]
                            del st.session_state.editing_index
                            st.session_state.processing = True
                            save_chat_history()
                            st.rerun()
                    with cols[1]:
                        if st.form_submit_button("‚ùå –û—Ç–º–µ–Ω–∞"):
                            del st.session_state.editing_index
                            st.rerun()
                    with cols[2]:
                        if st.form_submit_button("üóëÔ∏è –£–¥–∞–ª–∏—Ç—å"):
                            del st.session_state.chats[st.session_state.current_chat]["messages"][i]
                            del st.session_state.editing_index
                            st.rerun()
            
            else:
                cols = st.columns([8, 1])
                with cols[0]:
                    text = msg["content"]
                    parts = re.split(r'(<think>.*?</think>)', text, flags=re.DOTALL)
                    for part in parts:
                        if part.startswith('<think>') and '</think>' in part:
                            with st.expander("ü§î –ú—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å", expanded=False):
                                st.markdown(part)
                        else:
                            st.markdown(part)
                
                if msg["role"] == "user":
                    with cols[1]:
                        if st.button("‚úèÔ∏è", key=f"edit_{i}", help="–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç"):
                            st.session_state.editing_index = i
                            st.rerun()
                elif msg["role"] == "assistant":
                    with cols[1]:
                        if st.button("üîÑ", key=f"regenerate_{i}", help="–ü–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç"):
                            current_chat = st.session_state.chats[st.session_state.current_chat]["messages"]
                            st.session_state.chats[st.session_state.current_chat]["messages"] = current_chat[:i]
                            st.session_state.processing = True
                            save_chat_history()
                            st.rerun()

if st.button("üßπ –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é"):
    st.session_state.chats[st.session_state.current_chat]["messages"] = []
    st.session_state.processing = False
    save_chat_history()
    st.rerun()

with st.form("chat_form", clear_on_submit=True):
    user_input = st.text_area(
        "–í–∞—à –≤–æ–ø—Ä–æ—Å:" if st.session_state.mode == "RAG" else "–í–∞—à–µ —Å–æ–æ–±—â–µ–Ω–∏–µ:",
        placeholder="–í–≤–µ–¥–∏—Ç–µ –≤–∞—à —Ç–µ–∫—Å—Ç... (Shift+Enter –¥–ª—è –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏)",
        key="input",
        height=100
    )
    submit_button = st.form_submit_button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å")

if submit_button and user_input:
    if user_input.startswith("*sysmsg*"):
        cleaned_input = user_input.replace("*sysmsg*", "", 1).strip()
        st.session_state.chats[st.session_state.current_chat]["system_messages"].append(cleaned_input)
        save_chat_history()
        st.rerun()
    else:
        st.session_state.chats[st.session_state.current_chat]["messages"].append({
            "role": "user", 
            "content": user_input
        })
        st.session_state.processing = True
        save_chat_history()
        st.rerun()

def prepare_context(messages, system_messages):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    if not system_messages:
        return messages
    
    processed_messages = [msg.copy() for msg in messages]
    
    last_user_msg = None
    for msg in reversed(processed_messages):
        if msg["role"] == "user":
            last_user_msg = msg
            break
    
    if last_user_msg:
        system_block = "## System instructions:\n" + "\n".join(
            f"- {sm}" for sm in system_messages
        )
        last_user_msg["content"] = f"{system_block}\n## User query:\n{last_user_msg['content']}"
    
    return processed_messages

def process_response_chunks(stream_generator):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ—Ç–æ–∫–æ–≤—ã–µ —á–∞–Ω–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –±–ª–æ–∫–∞ <think>"""
    buffer = ""
    response_container = st.empty()
    spinner_placeholder = st.empty()

    with spinner_placeholder:
        st.spinner("ü§î –†–∞–∑–º—ã—à–ª–µ–Ω–∏–µ...")

    try:
        if st.session_state.mode == "RAG":
            for char in stream_generator:
                buffer += char
                spinner_placeholder.empty()
                response_container.markdown(buffer + "‚ñå")
        else:
            for chunk in stream_generator:
                delta = chunk.delta if hasattr(chunk, 'delta') else chunk
                buffer += delta
                spinner_placeholder.empty()
                response_container.markdown(buffer + "‚ñå")
    finally:
        spinner_placeholder.empty()

    response_container.empty()
    parts = re.split(r'(<think>.*?</think>)', buffer, flags=re.DOTALL)
    with response_container:
        for part in parts:
            if part.strip():
                if part.startswith('<think>') and '</think>' in part:
                    with st.expander("ü§î –ú—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å", expanded=False):
                        st.markdown(part)
                else:
                    st.markdown(part)
    
    return buffer

if st.session_state.processing:
    with st.spinner("üîç –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏..." if st.session_state.mode == "RAG" else "üí≠ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç..."):
        try:
            last_message = st.session_state.chats[st.session_state.current_chat]["messages"][-1]
            if last_message["role"] == "user":
                user_input = last_message["content"]
                
                if st.session_state.mode == "RAG":
                    with chat_container:
                        with st.chat_message("assistant", avatar="ü§ñ"):
                            stream_response = st.session_state.rag_info["query_engine"].query(user_input)
                            full_response = process_response_chunks(stream_response.response_gen)

                            sources = f"\n\n_Sources: {stream_response.source_nodes} documents_"
                            st.markdown(sources)
                            full_response += sources

                    st.session_state.chats[st.session_state.current_chat]["messages"].append({
                        "role": "assistant", 
                        "content": full_response
                    })
                else:
                    prepared_messages = prepare_context(
                        st.session_state.chats[st.session_state.current_chat]["messages"],
                        st.session_state.chats[st.session_state.current_chat]["system_messages"]
                    )
                    chat_history = [
                        ChatMessage(role=msg["role"], content=msg["content"])
                        for msg in prepared_messages
                    ]
                    with chat_container:
                        with st.chat_message("assistant", avatar="ü§ñ"):
                            stream_response = st.session_state.llm.stream_chat(chat_history)
                            full_response = process_response_chunks(stream_response)
                    
                    st.session_state.chats[st.session_state.current_chat]["messages"].append({
                        "role": "assistant", 
                        "content": full_response
                    })
            st.session_state.processing = False
            save_chat_history()
            st.rerun()

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")
            st.session_state.processing = False
